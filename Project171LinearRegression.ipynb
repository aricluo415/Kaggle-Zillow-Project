{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines\n",
    "YEAR = 2017\n",
    "THRESHOLD = .60\n",
    "FILL_NA = 0\n",
    "DATE_CONVERSION = 'timestamps'\n",
    "PREPROCESSING = 'MeanNormalization'\n",
    "KFOLD_SPLITS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def check_na(train):\n",
    "    # Finds the number of missing values in each column\n",
    "    num_of_na = [train.loc[:,col].isnull().sum() for col in train]\n",
    "    # Divide by rows for proportion \n",
    "    prop_na = [num / train.shape[0] for num in num_of_na]\n",
    "    # Put the proporitons and column names into a df and sort\n",
    "    na_df = pd.DataFrame({'prop_na' : prop_na, 'column' : train.columns}).sort_values('prop_na')\n",
    "    return na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csvs\n",
    "if YEAR == 2016:\n",
    "    properties = pd.read_csv('properties_2016.csv', low_memory = False)\n",
    "    train = pd.read_csv('train_2016_v2.csv', low_memory = False)\n",
    "elif YEAR == 2017:\n",
    "    properties = pd.read_csv('properties_2017.csv', low_memory = False)\n",
    "    train = pd.read_csv('train_2017.csv', low_memory = False)\n",
    "# train has Y and properties has features\n",
    "# Find row intersection of train and properties\n",
    "train = train.merge(properties, on = 'parcelid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns above the THRESHOLD\n",
    "train = train.loc[:, (train.isnull().sum(axis=0) <= (train.shape[0]*THRESHOLD))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NAs with number defined in FILL_NA\n",
    "# train = train.fillna(FILL_NA)\n",
    "# Convert transactiondate strings into floats\n",
    "date_strings = (train.values[:,2])\n",
    "date_converted = []\n",
    "if DATE_CONVERSION == 'timestamps':\n",
    "    for string in date_strings:\n",
    "        date_converted.append(time.mktime(datetime.datetime.strptime(string, \"%Y-%m-%d\").timetuple()))\n",
    "train['transactiondate'] = np.asarray(date_converted)\n",
    "# Drop the columns with string and int\n",
    "train = train.drop(columns=['propertycountylandusecode', 'propertyzoningdesc'])\n",
    "y = train.values[:,1]\n",
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalization\n",
    "if PREPROCESSING == \"MeanNormalization\":\n",
    "    train = (train - train.mean()) / (train.max() - train.min())\n",
    "# Fill the missing values\n",
    "train = train.fillna(FILL_NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of K-Fold Cross-Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     2     3 ... 77609 77611 77612] TEST: [    1    28    30 ... 77602 77607 77610]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [   10    24    25 ... 77586 77593 77595]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [    3    12    13 ... 77582 77603 77608]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [    8    23    40 ... 77567 77597 77599]\n",
      "TRAIN: [    0     1     3 ... 77610 77611 77612] TEST: [    2    11    22 ... 77569 77574 77605]\n",
      "TRAIN: [    0     1     2 ... 77609 77610 77611] TEST: [   33    37    39 ... 77585 77601 77612]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [   26    35    36 ... 77587 77588 77591]\n",
      "TRAIN: [    1     2     3 ... 77609 77610 77612] TEST: [    0     4     6 ... 77600 77606 77611]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [    5    41    49 ... 77592 77604 77609]\n",
      "TRAIN: [    0     1     2 ... 77610 77611 77612] TEST: [    9    15    18 ... 77589 77594 77596]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "x = train.values[:,2:]\n",
    "#if PREPROCESSING == 'MinMax':\n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(x)\n",
    "    #x = scaler.transform(x)\n",
    "# KFolds\n",
    "train_index_array = []\n",
    "test_index_array = []\n",
    "kf = KFold(n_splits = KFOLD_SPLITS, shuffle = True, random_state = 1)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_index_array.append(train_index)\n",
    "    test_index_array.append(test_index)\n",
    "MY_INDEX = 1\n",
    "x_train, x_test = x[train_index_array[MY_INDEX]], x[test_index_array[MY_INDEX]]\n",
    "y_train, y_test = y[train_index_array[MY_INDEX]], y[test_index_array[MY_INDEX]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Linear Regression\n",
    "##### For k-folds, set MY_INDEX variable as the desired fold index in the above cell and re-run the linear regression\n",
    "##### Execution of only one fold is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the model above is:  0.037502109792741566\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model = regr.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test) \n",
    "print(\"The MSE for the model above is: \", mse(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
